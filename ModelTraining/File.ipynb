{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ad79c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c413eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    QUANTITY  CLEANED_QUANTITY\n",
      "0       1 tr               1.0\n",
      "1    11/2 tr              11.0\n",
      "2   100 cups             100.0\n",
      "3   1,1/2 tr               1.0\n",
      "4   2 1/2 tr               2.0\n",
      "5     100 ps             100.0\n",
      "6       1 tr               1.0\n",
      "7       2 tr               2.0\n",
      "8        100             100.0\n",
      "9         40              40.0\n",
      "10    1 tray               1.0\n",
      "11      1 tr               1.0\n",
      "12        30              30.0\n",
      "13  1/2 Tray               1.0\n",
      "14  3/4 Tray               3.0\n",
      "15  1/2 Tray               1.0\n",
      "16    1 Tray               1.0\n",
      "17        30              30.0\n",
      "18  3/4 Tray               3.0\n",
      "19    1 Tray               1.0\n",
      "Number of missing cleaned quantities: 5\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Load the CSV file\n",
    "catering_details_df = pd.read_csv('tbl_catering_details.csv')\n",
    "\n",
    "# Function to extract numeric values from the QUANTITY column\n",
    "def extract_quantity(value):\n",
    "    if pd.isnull(value) or value.lower() == 'none':\n",
    "        return None\n",
    "    value = value.lower()\n",
    "    # Remove any non-numeric and non-decimal characters\n",
    "    numeric_value = re.findall(r'[\\d.]+', value)\n",
    "    if numeric_value:\n",
    "        return float(numeric_value[0])\n",
    "    return None\n",
    "\n",
    "# Apply the extraction function to the QUANTITY column\n",
    "catering_details_df['CLEANED_QUANTITY'] = catering_details_df['QUANTITY'].apply(extract_quantity)\n",
    "\n",
    "# Check the results and see how many values were successfully extracted\n",
    "cleaned_quantities_head = catering_details_df[['QUANTITY', 'CLEANED_QUANTITY']].head(20)\n",
    "missing_cleaned_quantities = catering_details_df['CLEANED_QUANTITY'].isnull().sum()\n",
    "\n",
    "print(cleaned_quantities_head)\n",
    "print(f\"Number of missing cleaned quantities: {missing_cleaned_quantities}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f8eb71d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_x</th>\n",
       "      <th>DELIVERY_DATE</th>\n",
       "      <th>DELIVERY_TIME</th>\n",
       "      <th>DELIVERY_MODE</th>\n",
       "      <th>DELIVERY_STATUS</th>\n",
       "      <th>INVOICE_AMOUNT</th>\n",
       "      <th>TAXES</th>\n",
       "      <th>CATERING_COST</th>\n",
       "      <th>SHOW_PRICE</th>\n",
       "      <th>DISCOUNT</th>\n",
       "      <th>...</th>\n",
       "      <th>CATEGORY_NAME</th>\n",
       "      <th>CATEGORY_ID</th>\n",
       "      <th>PRODUCT_NAME</th>\n",
       "      <th>UNIT</th>\n",
       "      <th>PRICE_y</th>\n",
       "      <th>IS_DAIRY_FREE</th>\n",
       "      <th>IS_GLUTEN_FREE</th>\n",
       "      <th>IS_NUT_FREE</th>\n",
       "      <th>IS_VEGAN</th>\n",
       "      <th>EXCLUDE_ITEM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13079</th>\n",
       "      <td>2796</td>\n",
       "      <td>4/7/2024</td>\n",
       "      <td>18:00:00</td>\n",
       "      <td>30</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1485.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1485.0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13080</th>\n",
       "      <td>2796</td>\n",
       "      <td>4/7/2024</td>\n",
       "      <td>18:00:00</td>\n",
       "      <td>30</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1485.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1485.0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13081</th>\n",
       "      <td>2796</td>\n",
       "      <td>4/7/2024</td>\n",
       "      <td>18:00:00</td>\n",
       "      <td>30</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1485.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1485.0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13082</th>\n",
       "      <td>2796</td>\n",
       "      <td>4/7/2024</td>\n",
       "      <td>18:00:00</td>\n",
       "      <td>30</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1485.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1485.0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13083</th>\n",
       "      <td>2797</td>\n",
       "      <td>7/31/2024</td>\n",
       "      <td>14:30:00</td>\n",
       "      <td>32</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID_x DELIVERY_DATE DELIVERY_TIME  DELIVERY_MODE DELIVERY_STATUS  \\\n",
       "13079  2796      4/7/2024      18:00:00             30            <NA>   \n",
       "13080  2796      4/7/2024      18:00:00             30            <NA>   \n",
       "13081  2796      4/7/2024      18:00:00             30            <NA>   \n",
       "13082  2796      4/7/2024      18:00:00             30            <NA>   \n",
       "13083  2797     7/31/2024      14:30:00             32            <NA>   \n",
       "\n",
       "       INVOICE_AMOUNT  TAXES  CATERING_COST  SHOW_PRICE  DISCOUNT  ...  \\\n",
       "13079          1485.0    0.0         1485.0           8       0.0  ...   \n",
       "13080          1485.0    0.0         1485.0           8       0.0  ...   \n",
       "13081          1485.0    0.0         1485.0           8       0.0  ...   \n",
       "13082          1485.0    0.0         1485.0           8       0.0  ...   \n",
       "13083             0.0    0.0          150.0           9       0.0  ...   \n",
       "\n",
       "       CATEGORY_NAME  CATEGORY_ID  PRODUCT_NAME  UNIT PRICE_y IS_DAIRY_FREE  \\\n",
       "13079            NaN          NaN           NaN   NaN     NaN           NaN   \n",
       "13080            NaN          NaN           NaN   NaN     NaN           NaN   \n",
       "13081            NaN          NaN           NaN   NaN     NaN           NaN   \n",
       "13082            NaN          NaN           NaN   NaN     NaN           NaN   \n",
       "13083            NaN          NaN           NaN   NaN     NaN           NaN   \n",
       "\n",
       "      IS_GLUTEN_FREE IS_NUT_FREE IS_VEGAN  EXCLUDE_ITEM  \n",
       "13079            NaN         NaN      NaN           NaN  \n",
       "13080            NaN         NaN      NaN           NaN  \n",
       "13081            NaN         NaN      NaN           NaN  \n",
       "13082            NaN         NaN      NaN           NaN  \n",
       "13083            NaN         NaN      NaN           NaN  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV files\n",
    "tbl_catering = pd.read_csv('tbl_catering.csv')\n",
    "tbl_catering_details = pd.read_csv('tbl_catering_details.csv')\n",
    "tbl_catering_products = pd.read_csv('tbl_catering_products.csv')\n",
    "\n",
    "# # Ensure the QUANTITY column is clean (using the earlier code)\n",
    "# # Example: catering_details_df['CLEANED_QUANTITY'] = ...\n",
    "\n",
    "# # Merge tbl_catering with tbl_catering_details\n",
    "# merged_df = pd.merge(tbl_catering, tbl_catering_details, left_on='ID', right_on='CATERING_ID', how='left')\n",
    "# final_df = pd.merge(merged_df, tbl_catering_products, left_on='ITEM_DESC', right_on='PRODUCT_NAME', how='left')\n",
    "\n",
    "# # Drop any unnecessary columns\n",
    "# final_df = final_df.drop(columns=['ID', 'CATERING_ID', 'PRODUCT_ID'])\n",
    "\n",
    "# # Display the first few rows of the final merged dataframe\n",
    "# print(final_df.head())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Data Cleaning\n",
    "tbl_catering.replace('\\\\N', pd.NA, inplace=True)\n",
    "tbl_catering_details.replace('\\\\N', pd.NA, inplace=True)\n",
    "tbl_catering_products.replace('\\\\N', pd.NA, inplace=True)\n",
    "\n",
    "# # Convert dates to datetime\n",
    "# tbl_catering['DELIVERY_DATE'] = pd.to_datetime(tbl_catering['DELIVERY_DATE'])\n",
    "# tbl_catering['DELIVERY_TIME'] = pd.to_datetime(tbl_catering['DELIVERY_TIME'], format='%H:%M:%S').dt.time\n",
    "\n",
    "# Fill missing values in numerical columns with 0\n",
    "num_cols = tbl_catering.select_dtypes(include='number').columns\n",
    "tbl_catering[num_cols] = tbl_catering[num_cols].fillna(0)\n",
    "\n",
    "# Data Merging\n",
    "merged_df = pd.merge(tbl_catering, tbl_catering_details, left_on='ID', right_on='CATERING_ID', how='left')\n",
    "final_df = pd.merge(merged_df, tbl_catering_products, left_on='ITEM_DESC', right_on='PRODUCT_NAME', how='left')\n",
    "\n",
    "# Display the first few rows of the final dataframe\n",
    "final_df.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba49b4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming we want to work with the 'QUANTITY' column, let's clean it first\n",
    "import re\n",
    "\n",
    "# Function to extract numeric values from the QUANTITY column\n",
    "def extract_quantity(value):\n",
    "    if pd.isnull(value) or value.lower() == 'none':\n",
    "        return None\n",
    "    value = value.lower()\n",
    "    numeric_value = re.findall(r'[\\d.]+', value)\n",
    "    if numeric_value:\n",
    "        return float(numeric_value[0])\n",
    "    return None\n",
    "\n",
    "# Clean the QUANTITY column\n",
    "final_df['CLEANED_QUANTITY'] = final_df['QUANTITY'].apply(extract_quantity)\n",
    "\n",
    "# Calculate the total quantity of each dish per event\n",
    "final_df['TOTAL_DISH_QUANTITY'] = final_df.groupby('ID_x')['CLEANED_QUANTITY'].transform('sum')\n",
    "\n",
    "# Calculate the average quantity of each dish per guest\n",
    "final_df['AVG_QUANTITY_PER_GUEST'] = final_df['CLEANED_QUANTITY'] / final_df['GUEST_COUNT']\n",
    "\n",
    "# Calculate the total cost per event\n",
    "final_df['TOTAL_COST'] = final_df.groupby('ID_x')['PRICE_x'].transform('sum')\n",
    "\n",
    "# Normalize the dish quantities by guest count\n",
    "final_df['NORMALIZED_QUANTITY'] = final_df['CLEANED_QUANTITY'] / final_df['GUEST_COUNT']\n",
    "\n",
    "# Prepare the data for modeling\n",
    "model_data = final_df[['GUEST_COUNT', 'PRODUCT_NAME', 'AVG_QUANTITY_PER_GUEST', 'TOTAL_COST', 'NORMALIZED_QUANTITY']]\n",
    "\n",
    "# One-hot encode the categorical variables (e.g., PRODUCT_NAME)\n",
    "model_data = pd.get_dummies(model_data, columns=['PRODUCT_NAME'], drop_first=True)\n",
    "\n",
    "# Display the first few rows of the prepared data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "64250b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming final_df is the merged dataframe from the previous steps\n",
    "\n",
    "# Convert the 'QUANTITY' and 'GUEST_COUNT' columns to numeric, forcing errors to NaN and then filling with 0\n",
    "final_df['QUANTITY'] = pd.to_numeric(final_df['QUANTITY'], errors='coerce').fillna(0)\n",
    "final_df['GUEST_COUNT'] = pd.to_numeric(final_df['GUEST_COUNT'], errors='coerce').fillna(0)\n",
    "\n",
    "# Step 1: Create aggregate features\n",
    "\n",
    "# Calculate the total quantity of each dish per event\n",
    "final_df['TOTAL_DISH_QUANTITY'] = final_df.groupby('ID_x')['QUANTITY'].transform('sum')\n",
    "\n",
    "# Calculate the average quantity of each dish per guest\n",
    "final_df['AVG_QUANTITY_PER_GUEST'] = final_df['QUANTITY'] / final_df['GUEST_COUNT']\n",
    "\n",
    "# Calculate the total cost per event using 'PRICE_x'\n",
    "final_df['TOTAL_COST'] = final_df.groupby('ID_x')['PRICE_x'].transform('sum')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "615335d3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nRandomForestRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m model \u001b[38;5;241m=\u001b[39m RandomForestRegressor(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Make predictions\u001b[39;00m\n\u001b[0;32m     22\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:348\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(y):\n\u001b[0;32m    347\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse multilabel-indicator for y is not supported.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 348\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[0;32m    349\u001b[0m     X, y, multi_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mDTYPE\n\u001b[0;32m    350\u001b[0m )\n\u001b[0;32m    351\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    352\u001b[0m     sample_weight \u001b[38;5;241m=\u001b[39m _check_sample_weight(sample_weight, X)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:621\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    619\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    620\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 621\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    622\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    624\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1147\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1142\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[0;32m   1143\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1144\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1145\u001b[0m     )\n\u001b[1;32m-> 1147\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m   1148\u001b[0m     X,\n\u001b[0;32m   1149\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[0;32m   1150\u001b[0m     accept_large_sparse\u001b[38;5;241m=\u001b[39maccept_large_sparse,\n\u001b[0;32m   1151\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m   1152\u001b[0m     order\u001b[38;5;241m=\u001b[39morder,\n\u001b[0;32m   1153\u001b[0m     copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m   1154\u001b[0m     force_all_finite\u001b[38;5;241m=\u001b[39mforce_all_finite,\n\u001b[0;32m   1155\u001b[0m     ensure_2d\u001b[38;5;241m=\u001b[39mensure_2d,\n\u001b[0;32m   1156\u001b[0m     allow_nd\u001b[38;5;241m=\u001b[39mallow_nd,\n\u001b[0;32m   1157\u001b[0m     ensure_min_samples\u001b[38;5;241m=\u001b[39mensure_min_samples,\n\u001b[0;32m   1158\u001b[0m     ensure_min_features\u001b[38;5;241m=\u001b[39mensure_min_features,\n\u001b[0;32m   1159\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[0;32m   1160\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1161\u001b[0m )\n\u001b[0;32m   1163\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[0;32m   1165\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:959\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    953\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    954\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    955\u001b[0m             \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[0;32m    956\u001b[0m         )\n\u001b[0;32m    958\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[1;32m--> 959\u001b[0m         _assert_all_finite(\n\u001b[0;32m    960\u001b[0m             array,\n\u001b[0;32m    961\u001b[0m             input_name\u001b[38;5;241m=\u001b[39minput_name,\n\u001b[0;32m    962\u001b[0m             estimator_name\u001b[38;5;241m=\u001b[39mestimator_name,\n\u001b[0;32m    963\u001b[0m             allow_nan\u001b[38;5;241m=\u001b[39mforce_all_finite \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    964\u001b[0m         )\n\u001b[0;32m    966\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_samples \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    967\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:124\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 124\u001b[0m _assert_all_finite_element_wise(\n\u001b[0;32m    125\u001b[0m     X,\n\u001b[0;32m    126\u001b[0m     xp\u001b[38;5;241m=\u001b[39mxp,\n\u001b[0;32m    127\u001b[0m     allow_nan\u001b[38;5;241m=\u001b[39mallow_nan,\n\u001b[0;32m    128\u001b[0m     msg_dtype\u001b[38;5;241m=\u001b[39mmsg_dtype,\n\u001b[0;32m    129\u001b[0m     estimator_name\u001b[38;5;241m=\u001b[39mestimator_name,\n\u001b[0;32m    130\u001b[0m     input_name\u001b[38;5;241m=\u001b[39minput_name,\n\u001b[0;32m    131\u001b[0m )\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:173\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[1;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[0;32m    159\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    160\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    161\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    171\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    172\u001b[0m     )\n\u001b[1;32m--> 173\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[1;31mValueError\u001b[0m: Input X contains NaN.\nRandomForestRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# Select features and target variable\n",
    "features = final_df[['GUEST_COUNT', 'CATEGORY_NAME', 'SPICE_LEVEL', 'PRICE_x', 'TOTAL_COST', 'AVG_QUANTITY_PER_GUEST']]\n",
    "target = final_df['QUANTITY']\n",
    "\n",
    "# Convert categorical features to dummy variables\n",
    "features = pd.get_dummies(features)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the model\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = model.score(X_test, y_test)\n",
    "\n",
    "print(f\"Mean Absolute Error: {mae}\")\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"R-squared: {r2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b2024427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GUEST_COUNT                         0\n",
      "PRICE_x                             0\n",
      "TOTAL_COST                          0\n",
      "AVG_QUANTITY_PER_GUEST              0\n",
      "CATEGORY_NAME_APPETIZER - NONVEG    0\n",
      "                                   ..\n",
      "SPICE_LEVEL_SPICY                   0\n",
      "SPICE_LEVEL_SWEET                   0\n",
      "SPICE_LEVEL_V MILD                  0\n",
      "SPICE_LEVEL_VERY  MILD              0\n",
      "SPICE_LEVEL_VERY MILD               0\n",
      "Length: 86, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "missing_values = features.isnull().sum()\n",
    "print(missing_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "257753ae",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['CATEGORY_NAME', 'SPICE_LEVEL'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Impute missing values for categorical features\u001b[39;00m\n\u001b[0;32m      8\u001b[0m categorical_imputer \u001b[38;5;241m=\u001b[39m SimpleImputer(strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmost_frequent\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 9\u001b[0m features[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCATEGORY_NAME\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSPICE_LEVEL\u001b[39m\u001b[38;5;124m'\u001b[39m]] \u001b[38;5;241m=\u001b[39m categorical_imputer\u001b[38;5;241m.\u001b[39mfit_transform(features[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCATEGORY_NAME\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSPICE_LEVEL\u001b[39m\u001b[38;5;124m'\u001b[39m]])\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:3767\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3765\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   3766\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 3767\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39m_get_indexer_strict(key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   3769\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   3770\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:5877\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   5874\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   5875\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 5877\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[0;32m   5879\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   5880\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   5881\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:5938\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   5936\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m use_interval_msg:\n\u001b[0;32m   5937\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 5938\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   5940\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m   5941\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Index(['CATEGORY_NAME', 'SPICE_LEVEL'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Impute missing values for numerical features\n",
    "numerical_imputer = SimpleImputer(strategy='mean')\n",
    "features[['GUEST_COUNT', 'PRICE_x', 'TOTAL_COST', 'AVG_QUANTITY_PER_GUEST']] = numerical_imputer.fit_transform(features[['GUEST_COUNT', 'PRICE_x', 'TOTAL_COST', 'AVG_QUANTITY_PER_GUEST']])\n",
    "\n",
    "# Impute missing values for categorical features\n",
    "categorical_imputer = SimpleImputer(strategy='most_frequent')\n",
    "features[['CATEGORY_NAME', 'SPICE_LEVEL']] = categorical_imputer.fit_transform(features[['CATEGORY_NAME', 'SPICE_LEVEL']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "006e8e38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['GUEST_COUNT', 'PRICE_x', 'TOTAL_COST', 'AVG_QUANTITY_PER_GUEST',\n",
      "       'CATEGORY_NAME_APPETIZER - NONVEG', 'CATEGORY_NAME_APPETIZER - VEG',\n",
      "       'CATEGORY_NAME_CHAAT ITEM', 'CATEGORY_NAME_CUSTOM DESSERTS',\n",
      "       'CATEGORY_NAME_ENTREE - CHICKEN', 'CATEGORY_NAME_ENTREE - VEG',\n",
      "       'CATEGORY_NAME_NOODLES', 'CATEGORY_NAME_SIDES',\n",
      "       'CATEGORY_NAME_TANDOOR - NONVEG', 'SPICE_LEVEL_0', 'SPICE_LEVEL_1',\n",
      "       'SPICE_LEVEL_1 TR', 'SPICE_LEVEL_1/2 TR',\n",
      "       'SPICE_LEVEL_6 MILD AND 6 MED', 'SPICE_LEVEL_BABY SPICE',\n",
      "       'SPICE_LEVEL_COMP', 'SPICE_LEVEL_ED', 'SPICE_LEVEL_EXTRA MILD',\n",
      "       'SPICE_LEVEL_GARLIC', 'SPICE_LEVEL_HIGH', 'SPICE_LEVEL_HOT',\n",
      "       'SPICE_LEVEL_LESS SWEET', 'SPICE_LEVEL_LIGHT SUGAR',\n",
      "       'SPICE_LEVEL_LIGHT SUGAR ADDED', 'SPICE_LEVEL_LITE SUGAR',\n",
      "       'SPICE_LEVEL_LITE SUGAR ADDED', 'SPICE_LEVEL_LOOK AT COMMENTS',\n",
      "       'SPICE_LEVEL_LOW', 'SPICE_LEVEL_M', 'SPICE_LEVEL_M ED',\n",
      "       'SPICE_LEVEL_MEC', 'SPICE_LEVEL_MED', 'SPICE_LEVEL_MED - HOT',\n",
      "       'SPICE_LEVEL_MED PLUS', 'SPICE_LEVEL_MED TO HOT',\n",
      "       'SPICE_LEVEL_MED TO LOW', 'SPICE_LEVEL_MEDIM', 'SPICE_LEVEL_MEDIUM',\n",
      "       'SPICE_LEVEL_MEDIUM SUGAR', 'SPICE_LEVEL_MEDIUM TO HOT',\n",
      "       'SPICE_LEVEL_MEDIUM-HOT', 'SPICE_LEVEL_MEDIUMB', 'SPICE_LEVEL_MEDIUN',\n",
      "       'SPICE_LEVEL_MEDUM', 'SPICE_LEVEL_MEIDUM', 'SPICE_LEVEL_MESIUM',\n",
      "       'SPICE_LEVEL_MID', 'SPICE_LEVEL_MIDL', 'SPICE_LEVEL_MILD',\n",
      "       'SPICE_LEVEL_MILD - MEDIUM', 'SPICE_LEVEL_MILD / MEDIUM',\n",
      "       'SPICE_LEVEL_MILD / MEIDUM', 'SPICE_LEVEL_MILD MEDIUM',\n",
      "       'SPICE_LEVEL_MILD TO MED', 'SPICE_LEVEL_MILD TO MEDIUM',\n",
      "       'SPICE_LEVEL_MILD-MED', 'SPICE_LEVEL_MILD-MEDIUM',\n",
      "       'SPICE_LEVEL_MILD/MED', 'SPICE_LEVEL_MILE', 'SPICE_LEVEL_MILKD',\n",
      "       'SPICE_LEVEL_MLLD', 'SPICE_LEVEL_Medium', 'SPICE_LEVEL_Meidum',\n",
      "       'SPICE_LEVEL_Mild', 'SPICE_LEVEL_N', 'SPICE_LEVEL_N/.A',\n",
      "       'SPICE_LEVEL_NAN', 'SPICE_LEVEL_NED', 'SPICE_LEVEL_NO',\n",
      "       'SPICE_LEVEL_NOE', 'SPICE_LEVEL_NOEN', 'SPICE_LEVEL_NOME',\n",
      "       'SPICE_LEVEL_NON', 'SPICE_LEVEL_NONE', 'SPICE_LEVEL_NOS',\n",
      "       'SPICE_LEVEL_NS', 'SPICE_LEVEL_PS', 'SPICE_LEVEL_SPICY',\n",
      "       'SPICE_LEVEL_SWEET', 'SPICE_LEVEL_V MILD', 'SPICE_LEVEL_VERY  MILD',\n",
      "       'SPICE_LEVEL_VERY MILD'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['Corrected_GUEST_COUNT', 'Corrected_PRICE_x', 'Corrected_TOTAL_COST',\\n       'Corrected_AVG_QUANTITY_PER_GUEST'],\\n      dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Impute missing values for numerical features\u001b[39;00m\n\u001b[0;32m      9\u001b[0m numerical_imputer \u001b[38;5;241m=\u001b[39m SimpleImputer(strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 10\u001b[0m features[corrected_numerical_columns] \u001b[38;5;241m=\u001b[39m numerical_imputer\u001b[38;5;241m.\u001b[39mfit_transform(features[corrected_numerical_columns])\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Impute missing values for categorical features\u001b[39;00m\n\u001b[0;32m     13\u001b[0m categorical_imputer \u001b[38;5;241m=\u001b[39m SimpleImputer(strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmost_frequent\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:3767\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3765\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   3766\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 3767\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39m_get_indexer_strict(key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   3769\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   3770\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:5877\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   5874\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   5875\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 5877\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[0;32m   5879\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   5880\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   5881\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:5938\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   5936\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m use_interval_msg:\n\u001b[0;32m   5937\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 5938\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   5940\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m   5941\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Index(['Corrected_GUEST_COUNT', 'Corrected_PRICE_x', 'Corrected_TOTAL_COST',\\n       'Corrected_AVG_QUANTITY_PER_GUEST'],\\n      dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "# Print available columns to verify\n",
    "print(features.columns)\n",
    "\n",
    "# Assuming you find the correct column names, update them in the imputation step\n",
    "corrected_numerical_columns = ['Corrected_GUEST_COUNT', 'Corrected_PRICE_x', 'Corrected_TOTAL_COST', 'Corrected_AVG_QUANTITY_PER_GUEST']\n",
    "corrected_categorical_columns = ['Corrected_CATEGORY_NAME', 'Corrected_SPICE_LEVEL']\n",
    "\n",
    "# Impute missing values for numerical features\n",
    "numerical_imputer = SimpleImputer(strategy='mean')\n",
    "features[corrected_numerical_columns] = numerical_imputer.fit_transform(features[corrected_numerical_columns])\n",
    "\n",
    "# Impute missing values for categorical features\n",
    "categorical_imputer = SimpleImputer(strategy='most_frequent')\n",
    "features[corrected_categorical_columns] = categorical_imputer.fit_transform(features[corrected_categorical_columns])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "629a8b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternatively, drop rows with any missing values\n",
    "features.dropna(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7464ae26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.7238292319449753\n",
      "Mean Squared Error: 44.29776853489109\n",
      "R-squared: 0.9952262522494487\n"
     ]
    }
   ],
   "source": [
    "# Split the data again if you've made changes to 'features'\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the model\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = model.score(X_test, y_test)\n",
    "\n",
    "print(f\"Mean Absolute Error: {mae}\")\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"R-squared: {r2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b104ff86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Assuming you have trained your model as `model`\n",
    "# For example:\n",
    "# model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "# model.fit(X_train, y_train)\n",
    "\n",
    "# Save the model to a file\n",
    "with open('trained_model.pkl', 'wb') as model_file:\n",
    "    pickle.dump(model, model_file)\n",
    "\n",
    "print(\"Model saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da7b560",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403efc47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562cecdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9f023e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29f8dfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f027869",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b7ad35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45636020",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71cb33e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
